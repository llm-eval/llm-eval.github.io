---
layout: page
title: LLM evaluation
permalink: /
subtitle: 

# profile:
#   align: right
#   image: prof_pic.jpg
#   image_circular: false # crops the image to make it circular
#   more_info: >
#     <p>555 your office number</p>
#     <p>123 your address street</p>
#     <p>Your City, State 12345</p>

# news: true  # includes a list of news items
# latest_posts: true  # includes a list of the newest posts
# selected_papers: true # includes a list of papers marked as "selected={true}"
# social: true  # includes social icons at the bottom of the page
---

<div align="center">
  <img src="https://github.com/MLGroupJLU/LLM-eval-survey/blob/main/imgs/logo-llmeval.png?raw=true" alt="LLM evaluation" width="500"><br>
  <strong>
    Original research on evaluation of LLMs conducted by Microsoft Research and other collaborated institutes. *(Updated at: 2023/10)*
  </strong><br>
  (Contact: <a href="https://jd92.wang/">Jindong Wang</a>, also see our projects on <a href="https://llm-enhance.github.io/">LLM enhancement</a>)
</div>
<br>

[![Button with Background Image](../assets/img/framework.png)](https://llm-eval.github.io/code/)


**PromptBench** is our unified library for evaluating and understanding large language models.

<!-- <p align="center">
<img src="../assets/img/framework.png" style="width: 60%;"/>
</p> -->